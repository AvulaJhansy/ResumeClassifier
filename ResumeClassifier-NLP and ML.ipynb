{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16a87e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "786e85ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Loading\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Avula Jhansy\\Downloads\\Resume\\archive\\UpdatedResumeDataSet.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5620729c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of rows and columns\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24ce52d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Java Developer               84\n",
       "Testing                      70\n",
       "DevOps Engineer              55\n",
       "Python Developer             48\n",
       "Web Designing                45\n",
       "HR                           44\n",
       "Hadoop                       42\n",
       "Blockchain                   40\n",
       "ETL Developer                40\n",
       "Operations Manager           40\n",
       "Data Science                 40\n",
       "Sales                        40\n",
       "Mechanical Engineer          40\n",
       "Arts                         36\n",
       "Database                     33\n",
       "Electrical Engineering       30\n",
       "Health and fitness           30\n",
       "PMO                          30\n",
       "Business Analyst             28\n",
       "DotNet Developer             28\n",
       "Automation Testing           26\n",
       "Network Security Engineer    25\n",
       "SAP Developer                24\n",
       "Civil Engineer               24\n",
       "Advocate                     20\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For each category unique values\n",
    "\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f64d6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning with NLP - removing urls, stop words, emails, special charecters\n",
    "\n",
    "def clean(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "    clean_text = url_pattern.sub('', text)\n",
    "    clean_text = email_pattern.sub('', clean_text)\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_text = ' '.join(word for word in clean_text.split() if word.lower() not in stop_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bec7346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying clean function to all rows \n",
    "df[\"Resume\"] = df[\"Resume\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48e00047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skills Programming Languages Python pandas numpy scipy scikitlearn matplotlib Sql Java JavaScriptJQuery Machine learning Regression SVM NaÃve Bayes KNN Random Forest Decision Trees Boosting techniques Cluster Analysis Word Embedding Sentiment Analysis Natural Language processing Dimensionality reduction Topic Modelling LDA NMF PCA Neural Nets Database Visualizations Mysql SqlServer Cassandra Hbase ElasticSearch D3js DCjs Plotly kibana matplotlib ggplot Tableau Others Regular Expression HTML CSS Angular 6 Logstash Kafka Python Flask Git Docker computer vision Open CV understanding Deep learningEducation Details Data Science Assurance Associate Data Science Assurance Associate Ernst Young LLP Skill Details JAVASCRIPT Exprience 24 months jQuery Exprience 24 months Python Exprience 24 monthsCompany Details company Ernst Young LLP description Fraud Investigations Dispute Services Assurance TECHNOLOGY ASSISTED REVIEW TAR Technology Assisted Review assists accelerating review process run analytics generate reports Core member team helped developing automated review platform tool scratch assisting E discovery domain tool implements predictive coding topic modelling automating reviews resulting reduced labor costs time spent lawyers review Understand end end flow solution research development classification models predictive analysis mining information present text data Worked analyzing outputs precision monitoring entire tool TAR assists predictive coding topic modelling evidence following EY standards Developed classifier models order identify red flags fraudrelated issues Tools Technologies Python scikitlearn tfidf word2vec doc2vec cosine similarity NaÃve Bayes LDA NMF topic modelling Vader text blob sentiment analysis Matplot lib Tableau dashboard reporting MULTIPLE DATA SCIENCE ANALYTIC PROJECTS USA CLIENTS TEXT ANALYTICS MOTOR VEHICLE CUSTOMER REVIEW DATA Received customer feedback survey data past one year Performed sentiment Positive Negative Neutral time series analysis customer comments across 4 categories Created heat map terms survey category based frequency words Extracted Positive Negative words across Survey categories plotted Word cloud Created customized tableau dashboards effective reporting visualizations CHATBOT Developed user friendly chatbot one Products handle simple questions hours operation reservation options chat bot serves entire product related questions Giving overview tool via QA platform also give recommendation responses user question build chain relevant answer intelligence build pipeline questions per user requirement asks relevant recommended questions Tools Technologies Python Natural language processing NLTK spacy topic modelling Sentiment analysis Word Embedding scikitlearn JavaScriptJQuery SqlServer INFORMATION GOVERNANCE Organizations make informed decisions information store integrated Information Governance portfolio synthesizes intelligence across unstructured data sources facilitates action ensure organizations best positioned counter information risk Scan data multiple sources formats parse different file formats extract Meta data information push results indexing elastic search created customized interactive dashboards using kibana Preforming ROT Analysis data give information data helps identify content either Redundant Outdated Trivial Preforming fulltext search analysis elastic search predefined methods tag PII personally identifiable information social security numbers addresses names etc frequently targeted cyberattacks Tools Technologies Python Flask Elastic Search Kibana FRAUD ANALYTIC PLATFORM Fraud Analytics investigative platform review red flag cases â FAP Fraud Analytics investigative platform inbuilt case manager suite Analytics various ERP systems used clients interrogate Accounting systems identifying anomalies indicators fraud running advanced analytics Tools Technologies HTML JavaScript SqlServer JQuery CSS Bootstrap Nodejs D3js DCjs'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Resume\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d240bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and vectorisation in NLP PIPLELINE\n",
    "label = LabelEncoder()\n",
    "label.fit(df['Category'])\n",
    "df['Category'] = label.transform(df['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f0dfcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 12,  0,  1, 24, 16, 22, 14,  5, 15,  4, 21,  2, 11, 18, 20,  8,\n",
       "       17, 19,  7, 13, 10,  9,  3, 23])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4119bce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<962x8017 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 169562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit the TF-IDF vectorizer on the 'Resume' column to learn the vocabulary and IDF of the words\n",
    "tfidf.fit(df[\"Resume\"])\n",
    "# Transform the 'Resume' texts into a sparse matrix of TF-IDF features\n",
    "resume = tfidf.transform(df[\"Resume\"])\n",
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14d91cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Skills Programming Languages Python pandas num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Education Details May 2013 May 2017 UITRGPV Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Areas Interest Deep Learning Control System De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Skills â R â Python â SAP HANA â Tableau â SAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Education Details MCA YMCAUST Faridabad Haryan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                             Resume\n",
       "0         6  Skills Programming Languages Python pandas num...\n",
       "1         6  Education Details May 2013 May 2017 UITRGPV Da...\n",
       "2         6  Areas Interest Deep Learning Control System De...\n",
       "3         6  Skills â R â Python â SAP HANA â Tableau â SAP...\n",
       "4         6  Education Details MCA YMCAUST Faridabad Haryan..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90dc83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(resume, df[\"Category\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea073f7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of KNeighborsClassifier:\n",
      "Accuracy: 0.98\n",
      "Precision: 0.99\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       1.00      0.60      0.75         5\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       0.88      1.00      0.93         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       0.78      1.00      0.88         7\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98       193\n",
      "   macro avg       0.99      0.98      0.98       193\n",
      "weighted avg       0.99      0.98      0.98       193\n",
      "\n",
      "--------------------------------------------------\n",
      "Performance of LogisticRegression:\n",
      "Accuracy: 0.99\n",
      "Precision: 1.00\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       0.88      1.00      0.93         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.99       193\n",
      "   macro avg       0.99      1.00      1.00       193\n",
      "weighted avg       1.00      0.99      0.99       193\n",
      "\n",
      "--------------------------------------------------\n",
      "Performance of RandomForestClassifier:\n",
      "Accuracy: 0.98\n",
      "Precision: 0.99\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       0.86      1.00      0.92        12\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       1.00      1.00      1.00        15\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       0.88      1.00      0.93         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98       193\n",
      "   macro avg       0.99      0.97      0.97       193\n",
      "weighted avg       0.99      0.98      0.98       193\n",
      "\n",
      "--------------------------------------------------\n",
      "Performance of SVC:\n",
      "Accuracy: 0.99\n",
      "Precision: 1.00\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       0.94      1.00      0.97        15\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       1.00      1.00      1.00         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.99       193\n",
      "   macro avg       1.00      1.00      1.00       193\n",
      "weighted avg       1.00      0.99      0.99       193\n",
      "\n",
      "--------------------------------------------------\n",
      "Performance of MultinomialNB:\n",
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      0.80      0.89         5\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       0.79      1.00      0.88        15\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00        12\n",
      "          19       1.00      1.00      1.00         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.98       193\n",
      "   macro avg       0.99      0.96      0.97       193\n",
      "weighted avg       0.98      0.98      0.98       193\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.984456</td>\n",
       "      <td>0.987406</td>\n",
       "      <td>0.984456</td>\n",
       "      <td>0.983885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994819</td>\n",
       "      <td>0.995466</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>0.994895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.984456</td>\n",
       "      <td>0.986584</td>\n",
       "      <td>0.984456</td>\n",
       "      <td>0.982341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.994819</td>\n",
       "      <td>0.995142</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>0.994806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.979275</td>\n",
       "      <td>0.983638</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>0.977519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy  precision    recall  f1_score\n",
       "KNeighborsClassifier    0.984456   0.987406  0.984456  0.983885\n",
       "LogisticRegression      0.994819   0.995466  0.994819  0.994895\n",
       "RandomForestClassifier  0.984456   0.986584  0.984456  0.982341\n",
       "SVC                     0.994819   0.995142  0.994819  0.994806\n",
       "MultinomialNB           0.979275   0.983638  0.979275  0.977519"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting and evaluation\n",
    "models = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'MultinomialNB': MultinomialNB()\n",
    "}\n",
    "evaluation_metrics = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "    evaluation_metrics[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    print(f'Performance of {model_name}:')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('-' * 50)\n",
    "pd.DataFrame(evaluation_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb6cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
